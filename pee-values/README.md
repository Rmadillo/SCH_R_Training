
<blockquote class="twitter-tweet" data-lang="en"><img src="https://cdn4.iconfinder.com/data/icons/bettericons/354/twitter-circle-512.png" width="100", height="100><p lang="en" dir="ltr"><br><br> "If you never use another p-value, you will have improved medicine.” <br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  -me, to clinicians <br><br>  <a href="https://twitter.com/hashtag/statstwitter?src=hash&amp;ref_src=twsrc%5Etfw"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #statstwitter</a> <a href="https://twitter.com/hashtag/medtwitter?src=hash&amp;ref_src=twsrc%5Etfw">#medtwitter</a> <a href="https://twitter.com/hashtag/epitwitter?src=hash&amp;ref_src=twsrc%5Etfw">#epitwitter</a></p><a href="https://twitter.com/healthstatsdude/status/1102442635233382400">&mdash; Grumpy Old Health Stats Dude (@healthstatsdude) March 4, 2019</a></blockquote>

<br>  
<hr>  
<br>  

<h2>Resources to accompany <i>The Only Good p-values Come from Catheters: Qualitative Philosophies and Quantitative Results in Pediatric Brain Surgery Outcomes</i></h2>  

Dwight Barry, PhD  
Principal Data Scientist  
Seattle Children's Hospital  

*Presented at the Advancing Analytics for Children's Hospitals conference, June 5-6, 2019, Ann & Robert H. Lurie Children’s Hospital of Chicago.*  

<h3>Link to Slides</h3>

https://github.com/Rmadillo/SCH_R_Training/blob/master/pee-values/Stats%20Philosophy%20Lurie%20201906%20lo%20res.pdf

<h3>Link to Code to Reproduce Analysis Shown in Slides</h3>

This analysis started in 2013 or 2014, so some of the code is fairly old. But I've tested it sucessfully on R version 3.5.1 on June 6, 2019. Please report any issues, and PRs welcome!

https://github.com/Rmadillo/SCH_R_Training/blob/master/pee-values/pee-values-R-code.R

<h3>Useful Resources</h3>  

*Completely new to the p-value problems? Start with these.* 

- Nuzzo, R. (2014). Scientific method: statistical errors. Nature, 506(7487), 150-152. https://www.nature.com/news/polopoly_fs/1.14700!/menu/main/topColumns/topLeftColumn/pdf/506150a.pdf

- Aschwanden, C. (2015). Science isn’t broken. It’s just a hell of a lot harder than we give it credit for. FiveThirtyEight. http://fivethirtyeight.com/features/science-isnt-broken 

- Wasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129-133.https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108  

- Bishop, D. (2019). Rein in the four horsemen of irreproducibility. Nature, 568(7753), 435. https://www.nature.com/articles/d41586-019-01307-2

- Wasserstein, R. L., Schirm, A. L., & Lazar, N. A. (2019). Moving to a world beyond “p< 0.05”. The American Statistician, 73:sup1, 1-19. https://amstat.tandfonline.com/doi/full/10.1080/00031305.2019.1583913

*Philosophies of statistical inference*  

- Goodman, S. N. (1993). P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate. American Journal of Epidemiology, 137(5), 485-496. https://pdfs.semanticscholar.org/7a46/007578dcfe0da282f0a6b22a47ba8b4a629a.pdf

- Stephens, P. A., Buskirk, S. W., & del Rio, C. M. (2007). Inference in ecology and evolution. Trends in Ecology & Evolution, 22(4), 192-197. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.457.424&rep=rep1&type=pdf

- Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference. Macmillan International Higher Education. https://www.amazon.com/Understanding-Psychology-Science-Introduction-Statistical/dp/023054231X

- Haig, B. D. (2014). The philosophy of quantitative methods. The Oxford handbook of quantitative methods, 7-31. https://books.google.com/books?id=98_QAgAAQBAJ&lpg=PA7&ots=q7_cxpKzO2&lr&pg=PA7#v=onepage&q&f=false

- Schneider, J. W. (2015). Null hypothesis significance tests. A mix-up of two different theories: the basis for widespread confusion and numerous misinterpretations. Scientometrics, 102(1), 411-432. https://pure.au.dk/ws/files/88918684/jws_scientometrics_resubmission.pdf

- Miguel A. Hernán, M.A., Hsu, J. & Healy, B. (2019). A second chance to get causal inference right: A classification of data science tasks. Chance, 32:1, 42-49. https://arxiv.org/abs/1804.10846

*Why "statistical significance" is a (very) bad thing*  

- Hauer, E. (2004). The harm done by tests of significance. Accident Analysis & Prevention, 36(3), 495-500. https://statmodeling.stat.columbia.edu/wp-content/uploads/2013/03/1154-Hauer-The-harm-done-by-tests-of-significance.pdf

- Ioannidis, J. P. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124. https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124  

- Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science, 22(11), 1359-1366. https://journals.sagepub.com/doi/pdf/10.1177/0956797611417632

- Ziliak, S. T. (2011). Matrixx v. Siracusano and Student v. Fisher: statistical significance on trial. Significance, 8(3), 131-134. https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2011.00511.x

- Lambdin, C. (2012). Significance tests as sorcery: Science is empirical—significance tests are not. Theory & Psychology, 22(1), 67-90. http://psychology.okstate.edu/faculty/jgrice/psyc5314/SignificanceSorceryLambdin2012.pdf

*Why p-values without significance don't help AT ALL*  

- Hubbard, R., & Lindsay, R. M. (2008). Why P values are not a useful measure of evidence in statistical significance testing. Theory & Psychology, 18(1), 69-88. https://www.researchgate.net/profile/R_Murray_Lindsay/publication/240281208_Why_P_Values_Are_Not_a_Useful_Measure_of_Evidence_in_Statistical_Significance_Testing/links/543fcf100cf2fd72f99dafd5.pdf  

- Johansson, T. (2011). Hail the impossible: p‐values, evidence, and likelihood. Scandinavian Journal of Psychology, 52(2), 113-125. https://www.ncbi.nlm.nih.gov/pubmed/21077903  

- Burnham, K. P., & Anderson, D. R. (2014). P values are only an index to evidence: 20th‐vs. 21st‐century statistical science. Ecology, 95(3), 627-630. https://pdfs.semanticscholar.org/ab54/a13747cbf1935926eb3853c432a2df8ab9fa.pdf

*Being a good Frequentist*  

- Coe, R. (2002). It’s the effect size, stupid: What effect size is and why it is important. Paper presented at the British Educational Research Association annual conference (Vol. 12, p. 14). http://www.leeds.ac.uk/educol/documents/00002182.htm

- Höhle, M. (2017). Confidence intervals without your collaborator's tears. Blog post.  http://staff.math.su.se/hoehle/blog/2017/06/22/interpretcis.html

- Ho, J., Tumkaya, T., Aryal, S., Choi, H., & Claridge-Chang, A. (2018). Moving beyond P values: Everyday data analysis with estimation plots. BioRxiv, 377978. https://www.biorxiv.org/content/10.1101/377978v2 & https://github.com/ACCLAB/dabestr

- Rousselet, G., Pernet, C., & Wilcox, R. R. (2019). A practical introduction to the bootstrap: a versatile method to make inferences by using data-driven simulations. PsyArXiv. https://psyarxiv.com/h8ft7/

- Frank Harrell and 33 others. (2019). Language for communicating frequentist results about treatment effects. Blog post and discussion. https://discourse.datamethods.org/t/language-for-communicating-frequentist-results-about-treatment-effects/934/21

- Assel, M., Sjoberg, D., Elders, A., Wang, X., Huo, D., Botchway, A., Delfino, K., Fan, Y., Zhao, Z., Koyama, T., Hollenbeck, B., Qin, R., Zahnd, W., Zabor, E., Kattan, M., Vickers, A. (2019). Guidelines for reporting of statistics for clinical research in urology. BJU international, 123(3), 401-410. https://onlinelibrary.wiley.com/doi/full/10.1111/bju.14640

*Intro to Bayesian methods*  

- Kruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic bulletin & review, 25(1), 155-177. https://link.springer.com/article/10.3758/s13423-017-1272-1

- Kruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573-603. https://www.youtube.com/watch?v=fhw1j1Ru2i0, http://www.indiana.edu/~kruschke/articles/Kruschke2013JEPG.pdf

- McElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman and Hall/CRC. https://www.amazon.com/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/1482253445/, https://www.youtube.com/playlist?list=PLDcUM9US4XdNM4Edgs7weiyIguLSToZRI (If you're going to choose just one reference to (re)learn stats, this should be it.)

- Ryan, E. G., Harrison, E. M., Pearse, R. M., & Gates, S. (2019). Perioperative haemodynamic therapy for major gastrointestinal surgery: the effect of a Bayesian approach to interpreting the findings of a randomised controlled trial. BMJ Open, 9(3), e024256. https://bmjopen.bmj.com/content/9/3/e024256

*The Information-Theoretic/Multi-model inference approach* 

- David Anderson. (2007). Alternatives to a p-value in simple "t-tests". https://sites.warnercnr.colostate.edu/anderson/wp-content/uploads/sites/26/2016/11/PDF-of-t_test_ANOVA_-with-I-T_final.pdf

- Anderson, D. R. (2010). Model based inference in the life sciences: a primer on evidence. Springer Science & Business Media. https://www.amazon.com/Model-Based-Inference-Life-Sciences/dp/0387740732/  

- Burnham, K. P., Anderson, D. R., & Huyvaert, K. P. (2011). AIC model selection and multimodel inference in behavioral ecology: some background, observations, and comparisons. Behavioral ecology and sociobiology, 65(1), 23-35. https://www.researchgate.net/profile/Kathryn_Kate_Huyvaert/publication/226414589_Erratum_to_AIC_model_selection_and_multimodel_inference_in_behavioral_ecology_some_background_observations_and_comparisons/links/09e415085a074899be000000.pdf

- Symonds, M. R., & Moussalli, A. (2011). A brief guide to model selection, multimodel inference and model averaging in behavioural ecology using Akaike’s information criterion. Behavioral Ecology and Sociobiology, 65(1), 13-21. https://cals.arizona.edu/classes/wfsc578/Symonds%20and%20Moussali%202011.%20A%20brief%20guide%20to%20model%20selection.pdf

*Model selection and model averaging after you've discarded Frequentism*  

- Posada, D., & Buckley, T. R. (2004). Model selection and model averaging in phylogenetics: advantages of Akaike information criterion and Bayesian approaches over likelihood ratio tests. Systematic biology, 53(5), 793-808. https://academic.oup.com/sysbio/article/53/5/793/2842928

*Pushing back against bad peer-review/editorial feedback on statistic*

- https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787

*SPSS-like GUIs that provide more modern stats methods for those who don't code*  

- JASP: https://jasp-stats.org/

- JAMOVI: https://www.jamovi.org/

- Adam Claridge-Chang and Joses Ho. (2019). Estimation Stats. https://www.estimationstats.com/

- Rasmus Bååth. (2012). Bayesian Estimation Supersedes the t-test (BEST) - online. http://sumsar.net/best_online/

*Discussions*

- DataMethods blog: https://discourse.datamethods.org/

- Twitter hashtags: #EpiTwitter #StatsTwitter  

<br>
<hr> 
<br> 
  
[![Significant](https://imgs.xkcd.com/comics/significant.png)](https://xkcd.com/882/)

<br>
<hr> 
<br> 

[![License: CC0-1.0](https://www.fairkom.eu/sites/default/files/styles/article_full/public/images/cc0-300x169.png)](http://creativecommons.org/publicdomain/zero/1.0/)
